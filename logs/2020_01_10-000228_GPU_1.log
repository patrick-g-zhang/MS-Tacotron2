
WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

FP16 Run: True
Dynamic Loss Scaling: True
Distributed Run: True
cuDNN Enabled: True
cuDNN Benchmark: False
Initializing Distributed
Done initializing distributed
Warm starting model from checkpoint './outdir5/tacotron2_statedict.pt'
Epoch: 0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Epoch: 1
Epoch: 2
Epoch: 3
Epoch: 4
Epoch: 5
Epoch: 6
Epoch: 7
Epoch: 8
Epoch: 9
Epoch: 10
Epoch: 11
Epoch: 12
Epoch: 13
Epoch: 14
Epoch: 15
Epoch: 16
Epoch: 17
Epoch: 18
Epoch: 19
Epoch: 20
Epoch: 21
Epoch: 22
Epoch: 23
Epoch: 24
Epoch: 25
Epoch: 26
Epoch: 27
Epoch: 28
Epoch: 29
Epoch: 30
Epoch: 31
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 32
Epoch: 33
Epoch: 34
Epoch: 35
Epoch: 36
Epoch: 37
Epoch: 38
Epoch: 39
Epoch: 40
Epoch: 41
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Epoch: 42
Epoch: 43
Epoch: 44
Epoch: 45
Epoch: 46
Epoch: 47
Epoch: 48
Epoch: 49
Epoch: 50
Epoch: 51
Epoch: 52
Epoch: 53
Epoch: 54
Epoch: 55
Epoch: 56
Epoch: 57
Epoch: 58
Epoch: 59
Epoch: 60
Epoch: 61
Epoch: 62
Epoch: 63
Epoch: 64
Epoch: 65
Epoch: 66
Epoch: 67
Epoch: 68
Epoch: 69
Epoch: 70
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 71
Epoch: 72
Epoch: 73
Epoch: 74
Epoch: 75
Epoch: 76
Epoch: 77
Epoch: 78
Epoch: 79
Epoch: 80
Epoch: 81
Epoch: 82
Epoch: 83
Epoch: 84
Epoch: 85
Epoch: 86
Epoch: 87
Epoch: 88
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 89
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Epoch: 90
Epoch: 91
Epoch: 92
Epoch: 93
Epoch: 94
Epoch: 95
Epoch: 96
Epoch: 97
Epoch: 98
Epoch: 99
Epoch: 100
Epoch: 101
Epoch: 102
Epoch: 103
Epoch: 104
Epoch: 105
Epoch: 106
Epoch: 107
Epoch: 108
Epoch: 109
Epoch: 110
Epoch: 111
Epoch: 112
Epoch: 113
Epoch: 114
Epoch: 115
Epoch: 116
Epoch: 117
Epoch: 118
Epoch: 119
Epoch: 120
Epoch: 121
Epoch: 122
Epoch: 123
Epoch: 124
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 125
Epoch: 126
Epoch: 127
Epoch: 128
Epoch: 129
Epoch: 130
Epoch: 131
Epoch: 132
Epoch: 133
Epoch: 134
Epoch: 135
Epoch: 136
Epoch: 137
Epoch: 138
Epoch: 139
Epoch: 140
Epoch: 141
Epoch: 142
Epoch: 143
Epoch: 144
Epoch: 145
Epoch: 146
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 147
Epoch: 148
Epoch: 149
Epoch: 150
Epoch: 151
Epoch: 152
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Epoch: 153
Epoch: 154
Epoch: 155
Epoch: 156
Epoch: 157
Epoch: 158
Epoch: 159
Epoch: 160
Epoch: 161
Epoch: 162
Epoch: 163
Epoch: 164
Epoch: 165
Epoch: 166
Epoch: 167
Epoch: 168
Epoch: 169
Epoch: 170
Epoch: 171
Epoch: 172
Epoch: 173
Epoch: 174
Epoch: 175
Epoch: 176
Epoch: 177
Epoch: 178
Epoch: 179
Epoch: 180
Epoch: 181
Epoch: 182
Epoch: 183
Epoch: 184
Epoch: 185
Epoch: 186
Epoch: 187
Epoch: 188
Epoch: 189
Epoch: 190
Epoch: 191
Epoch: 192
Epoch: 193
Epoch: 194
Epoch: 195
Epoch: 196
Epoch: 197
Epoch: 198
Epoch: 199
Epoch: 200
Epoch: 201
Epoch: 202
Epoch: 203
Epoch: 204
Epoch: 205
Epoch: 206
Epoch: 207
Epoch: 208
Epoch: 209
Epoch: 210
Epoch: 211
Epoch: 212
Epoch: 213
Epoch: 214
Epoch: 215
Epoch: 216
Epoch: 217
Epoch: 218
Epoch: 219
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch: 220
Epoch: 221
Epoch: 222
Epoch: 223
Epoch: 224
Epoch: 225
Epoch: 226
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch: 227
Epoch: 228
Epoch: 229
Epoch: 230
Epoch: 231
Epoch: 232
Epoch: 233
Epoch: 234
Epoch: 235
Epoch: 236
Epoch: 237
Epoch: 238
Epoch: 239
Epoch: 240
Epoch: 241
Epoch: 242
Epoch: 243
Epoch: 244
Epoch: 245
Epoch: 246
Epoch: 247
Epoch: 248
Epoch: 249
Epoch: 250
Epoch: 251
Epoch: 252
Epoch: 253
Epoch: 254
Epoch: 255
Epoch: 256
Epoch: 257
Epoch: 258
Epoch: 259
Epoch: 260
Epoch: 261
Epoch: 262
Epoch: 263
Epoch: 264
Epoch: 265
Epoch: 266
Epoch: 267
Epoch: 268
Epoch: 269
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch: 270
Epoch: 271
Epoch: 272
Epoch: 273
Epoch: 274
Epoch: 275
Epoch: 276
Epoch: 277
Epoch: 278
Epoch: 279
Epoch: 280
Epoch: 281
Epoch: 282
Epoch: 283
Epoch: 284
Epoch: 285
Epoch: 286
Epoch: 287
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Epoch: 288
Epoch: 289
Epoch: 290
Epoch: 291
Epoch: 292
Epoch: 293
Epoch: 294
Epoch: 295
Epoch: 296
Epoch: 297
Epoch: 298
Epoch: 299
Epoch: 300
Epoch: 301
Epoch: 302
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch: 303
Epoch: 304
Epoch: 305
Epoch: 306
Epoch: 307
Epoch: 308
Epoch: 309
Epoch: 310
Epoch: 311
Epoch: 312
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 313
Epoch: 314
Epoch: 315
Epoch: 316
Epoch: 317
Epoch: 318
Epoch: 319
Epoch: 320
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Epoch: 321
Epoch: 322
Epoch: 323
Epoch: 324
Epoch: 325
Epoch: 326
Epoch: 327
Epoch: 328
Epoch: 329
Epoch: 330
Epoch: 331
Epoch: 332
Epoch: 333
Epoch: 334
Epoch: 335
Epoch: 336
Epoch: 337
Epoch: 338
Epoch: 339
Epoch: 340
Epoch: 341
Epoch: 342
Epoch: 343
Epoch: 344
Epoch: 345
Epoch: 346
Epoch: 347
Epoch: 348
Epoch: 349
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 350
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Epoch: 351
Epoch: 352
Epoch: 353
Epoch: 354
Epoch: 355
Epoch: 356
Epoch: 357
Epoch: 358
Epoch: 359
Epoch: 360
Epoch: 361
Epoch: 362
Epoch: 363
Epoch: 364
Epoch: 365
Epoch: 366
Epoch: 367
Epoch: 368
Epoch: 369
Epoch: 370
Epoch: 371
Epoch: 372
Epoch: 373
Epoch: 374
Epoch: 375
Epoch: 376
Epoch: 377
Epoch: 378
Epoch: 379
Epoch: 380
Epoch: 381
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 382
Epoch: 383
Epoch: 384
Epoch: 385
Epoch: 386
Epoch: 387
Epoch: 388
Epoch: 389
Epoch: 390
Epoch: 391
Epoch: 392
Epoch: 393
Epoch: 394
Epoch: 395
Epoch: 396
Epoch: 397
Epoch: 398
Epoch: 399
Epoch: 400
Epoch: 401
Epoch: 402
Epoch: 403
Epoch: 404
Epoch: 405
Epoch: 406
Epoch: 407
Epoch: 408
Epoch: 409
Epoch: 410
Epoch: 411
Epoch: 412
Epoch: 413
Epoch: 414
Epoch: 415
Epoch: 416
Epoch: 417
Epoch: 418
Epoch: 419
Epoch: 420
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Epoch: 421
Epoch: 422
Epoch: 423
Epoch: 424
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Epoch: 425
Epoch: 426
Epoch: 427
Epoch: 428
Epoch: 429
Epoch: 430
Epoch: 431
Epoch: 432
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0
Epoch: 433
Epoch: 434
Epoch: 435
Epoch: 436
Epoch: 437
Epoch: 438
Epoch: 439
Epoch: 440
Epoch: 441
Epoch: 442
Epoch: 443
